{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import uuid\n",
    "import os\n",
    "import streamlit as st  \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load api key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads in a order file, splits it into chunks, creates embeddings, builds a vectorstore, initializes a LLM and the respective prompt of it. Splitting documents into smaller Chunks is necessary since feeding the LLM with all of it could confuse it. Embedding are textual respresentation of words in a multi-dimensional vector space. The distances of each vector are in relation to the contect or meaning of words to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PDF\n",
    "loader = PyPDFLoader(\"data/titanfreight_order.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split document due to token limits of llm's\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400,                 # max size for each chunk (in characters)\n",
    "                                            chunk_overlap=60,                  # how many characters overlap betw. chunks\n",
    "                                            length_function=len,               # to measure chunk length\n",
    "                                            separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings so llm can process data\n",
    "\n",
    "def get_embedding_function():             \n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\", openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding_function = get_embedding_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector database\n",
    "\n",
    "def create_vectorstore(chunks, embedding_function, vectorstore_path):\n",
    "\n",
    "    # Create a list of unique ids for each document based on the content (no duplicates)\n",
    "    ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in chunks]\n",
    "    \n",
    "    # Ensure that only unique docs with unique ids are kept\n",
    "    unique_ids = set()\n",
    "    unique_chunks = []\n",
    "    \n",
    "    for chunk, id in zip(chunks, ids):     \n",
    "        if id not in unique_ids:       \n",
    "            unique_ids.add(id)\n",
    "            unique_chunks.append(chunk) \n",
    "\n",
    "    # Create a new Chroma database from the documents\n",
    "    vectorstore = Chroma.from_documents(documents=unique_chunks, \n",
    "                                        ids=list(unique_ids),\n",
    "                                        embedding=embedding_function,\n",
    "                                        persist_directory = vectorstore_path)\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = create_vectorstore(chunks=chunks, \n",
    "                                 embedding_function=embedding_function,\n",
    "                                 vectorstore_path=\"vectorstore_chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorstore\n",
    "vectorstore = Chroma(persist_directory=\"vectorstore_chroma\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for extracting information out of documents (transport orders).\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. \n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Execute the following request: {question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the LLM uses the vectorstore and the generated embeddings and to create a dataframe, organizing the data into predefined columns with the corresponding data from the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to combine several documents into one and seperating them by two breaks (\\n)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate structured responses\n",
    "\n",
    "class AnswerWithSources(BaseModel):\n",
    "    \"\"\"An answer to the question, with sources and reasoning.\"\"\"\n",
    "    answer: str = Field(description=\"Answer to question\")\n",
    "    \n",
    "class ExtractedInfo(BaseModel):\n",
    "    \"\"\"Extracted information about the research article\"\"\"\n",
    "    Orderer: AnswerWithSources\n",
    "    Loading_location: AnswerWithSources\n",
    "    Unloading_location: AnswerWithSources\n",
    "    Loading_date: AnswerWithSources\n",
    "    Loading_time_window: AnswerWithSources\n",
    "    Unloading_date: AnswerWithSources\n",
    "    Unloading_time_window: AnswerWithSources\n",
    "    Goods: AnswerWithSources\n",
    "    Weight: AnswerWithSources\n",
    "    ADR: AnswerWithSources\n",
    "    Loading_number: AnswerWithSources\n",
    "    Transport_rate: AnswerWithSources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm.with_structured_output(ExtractedInfo, strict=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orderer</th>\n",
       "      <th>Loading_location</th>\n",
       "      <th>Unloading_location</th>\n",
       "      <th>Loading_date</th>\n",
       "      <th>Loading_time_window</th>\n",
       "      <th>Unloading_date</th>\n",
       "      <th>Unloading_time_window</th>\n",
       "      <th>Goods</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ADR</th>\n",
       "      <th>Loading_number</th>\n",
       "      <th>Transport_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>Titan Freight Solutions</td>\n",
       "      <td>Waldstraße 22, 44137 Dortmund</td>\n",
       "      <td>Hauptstraße 56, 60329 Frankfurt</td>\n",
       "      <td>November 20, 2024</td>\n",
       "      <td>09:00 AM to 11:00 AM</td>\n",
       "      <td>November 20, 2024</td>\n",
       "      <td>03:00 PM to 05:00 PM</td>\n",
       "      <td>25 pallets of construction materials</td>\n",
       "      <td>5,000 kilograms</td>\n",
       "      <td>No hazardous goods involved</td>\n",
       "      <td>Not specified in the provided context</td>\n",
       "      <td>€2,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Orderer               Loading_location  \\\n",
       "answer  Titan Freight Solutions  Waldstraße 22, 44137 Dortmund   \n",
       "\n",
       "                     Unloading_location       Loading_date  \\\n",
       "answer  Hauptstraße 56, 60329 Frankfurt  November 20, 2024   \n",
       "\n",
       "         Loading_time_window     Unloading_date Unloading_time_window  \\\n",
       "answer  09:00 AM to 11:00 AM  November 20, 2024  03:00 PM to 05:00 PM   \n",
       "\n",
       "                                       Goods           Weight  \\\n",
       "answer  25 pallets of construction materials  5,000 kilograms   \n",
       "\n",
       "                                ADR                         Loading_number  \\\n",
       "answer  No hazardous goods involved  Not specified in the provided context   \n",
       "\n",
       "       Transport_rate  \n",
       "answer         €2,000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform response into a dataframe \n",
    "\n",
    "structured_response = rag_chain.invoke(\"Give me the ordering company, full loading location, full unloading location, loading date, loading time window, unloading date, unloading time window, type of shipment goods, weight, indication of ADR, loading number, transport rate.\")\n",
    "df = pd.DataFrame([structured_response.dict()])\n",
    "\n",
    "answer_row = []\n",
    "\n",
    "for col in df.columns:\n",
    "    answer_row.append(df[col][0]['answer'])\n",
    "\n",
    "# Create new dataframe\n",
    "df_orderlist = pd.DataFrame([answer_row], columns=df.columns, index=['answer'])\n",
    "df_orderlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQL table and save order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a sqlite database and appends the data of each processed file to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite connection\n",
    "conn = sqlite3.connect(\"order_list.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Creatomg a table with a primary key\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS order_list (\n",
    "    id_column INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Orderer TEXT,\n",
    "    Loading_location TEXT,\n",
    "    Unloading_location TEXT,\n",
    "    Loading_date TEXT,\n",
    "    Loading_time_window TEXT,\n",
    "    Unloading_date TEXT,\n",
    "    Unloading_time_window TEXT,\n",
    "    Goods TEXT,\n",
    "    Weight TEXT,\n",
    "    ADR TEXT,\n",
    "    Loading_number TEXT,\n",
    "    Transport_rate TEXT\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Open the SQLite connection\n",
    "conn = sqlite3.connect(\"order_list.db\")\n",
    "\n",
    "# Save the DataFrame to the SQLite database\n",
    "df_orderlist.to_sql(\"order_list\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query SQL table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the database gets loaded and queried with a preset query which can be adjusted as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_column</th>\n",
       "      <th>Orderer</th>\n",
       "      <th>Loading_location</th>\n",
       "      <th>Unloading_location</th>\n",
       "      <th>Loading_date</th>\n",
       "      <th>Loading_time_window</th>\n",
       "      <th>Unloading_date</th>\n",
       "      <th>Unloading_time_window</th>\n",
       "      <th>Goods</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ADR</th>\n",
       "      <th>Loading_number</th>\n",
       "      <th>Transport_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Titan Freight Solutions</td>\n",
       "      <td>Waldstraße 22, 44137 Dortmund</td>\n",
       "      <td>Hauptstraße 56, 60329 Frankfurt</td>\n",
       "      <td>November 20, 2024</td>\n",
       "      <td>09:00 AM to 11:00 AM</td>\n",
       "      <td>November 20, 2024</td>\n",
       "      <td>03:00 PM to 05:00 PM</td>\n",
       "      <td>25 pallets of construction materials</td>\n",
       "      <td>5,000 kilograms</td>\n",
       "      <td>No hazardous goods involved</td>\n",
       "      <td>Not specified in the provided context</td>\n",
       "      <td>€2,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_column                  Orderer               Loading_location  \\\n",
       "0          1  Titan Freight Solutions  Waldstraße 22, 44137 Dortmund   \n",
       "\n",
       "                Unloading_location       Loading_date   Loading_time_window  \\\n",
       "0  Hauptstraße 56, 60329 Frankfurt  November 20, 2024  09:00 AM to 11:00 AM   \n",
       "\n",
       "      Unloading_date Unloading_time_window  \\\n",
       "0  November 20, 2024  03:00 PM to 05:00 PM   \n",
       "\n",
       "                                  Goods           Weight  \\\n",
       "0  25 pallets of construction materials  5,000 kilograms   \n",
       "\n",
       "                           ADR                         Loading_number  \\\n",
       "0  No hazardous goods involved  Not specified in the provided context   \n",
       "\n",
       "  Transport_rate  \n",
       "0         €2,000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"order_list.db\")\n",
    "\n",
    "# Query to check if the table exists and view its contents\n",
    "query = \"SELECT * FROM order_list LIMIT 5;\"  # Adjust LIMIT for more rows\n",
    "result = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Print the result\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
